package main

import (
	"bufio"
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"os/signal"
	"path/filepath"
	"strings"
	"sync"
	"syscall"
	"time"
)

// Book generation state
type BookGenerationState struct {
	BookNumber      int                    `json:"book_number"`
	Theme           BookTheme              `json:"theme"`
	Outline         *BookOutline           `json:"outline"`
	CurrentPhase    int                    `json:"current_phase"`
	PhaseResults    map[string]interface{} `json:"phase_results"`
	StartTime       time.Time              `json:"start_time"`
	LastUpdateTime  time.Time              `json:"last_update_time"`
	Status          string                 `json:"status"`
	OutputDirectory string                 `json:"output_directory"`
}

// Phase configuration for the pipeline
type PhaseInfo struct {
	Number      int    `json:"number"`
	Name        string `json:"name"`
	Directory   string `json:"directory"`
	Description string `json:"description"`
	InputFile   string `json:"input_file"`
	OutputFile  string `json:"output_file"`
}

// Enhanced Sequential Book Generator with logging, resume, pause, and chunked operations
type EnhancedSequentialGenerator struct {
	Model             string                   `json:"model"`
	BookQueue         []BookTheme              `json:"book_queue"`
	CurrentBook       int                      `json:"current_book"`
	TotalBooks        int                      `json:"total_books"`
	OutputDir         string                   `json:"output_dir"`
	Phases            []PhaseInfo              `json:"phases"`
	
	// Enhanced functionality
	ProgressTracker   *ProgressTracker         `json:"progress_tracker"`
	SessionState      *SessionState            `json:"session_state"`
	ChunkSize         int                      `json:"chunk_size"`
	AutoSaveInterval  time.Duration            `json:"auto_save_interval"`
	logger            *TerminalLogger          `json:"-"`
	
	// Control channels
	pauseChannel      chan bool                `json:"-"`
	stopChannel       chan bool                `json:"-"`
	resumeChannel     chan bool                `json:"-"`
	
	// State management
	mutex             sync.RWMutex             `json:"-"`
	paused            bool                     `json:"paused"`
	stopped           bool                     `json:"stopped"`
	stateFile         string                   `json:"state_file"`
}

// Session state for resumption
type SessionState struct {
	SessionID          string                  `json:"session_id"`
	StartTime          time.Time               `json:"start_time"`
	LastSaveTime       time.Time               `json:"last_save_time"`
	CurrentOperation   string                  `json:"current_operation"`
	BooksCompleted     []int                   `json:"books_completed"`
	BooksFailed        []int                   `json:"books_failed"`
	CurrentBookState   *BookGenerationState    `json:"current_book_state"`
	CanResume          bool                    `json:"can_resume"`
	ResumePoint        ResumePoint             `json:"resume_point"`
}

// Resume point information
type ResumePoint struct {
	BookNumber         int                     `json:"book_number"`
	PhaseNumber        int                     `json:"phase_number"`
	Operation          string                  `json:"operation"`
	CompletedSteps     []string                `json:"completed_steps"`
	NextSteps          []string                `json:"next_steps"`
}

// Enhanced phase info with chunking capabilities
type EnhancedPhaseInfo struct {
	PhaseInfo
	Chunks             []ChunkInfo             `json:"chunks"`
	CanChunk           bool                    `json:"can_chunk"`
	ChunkDependencies  []string                `json:"chunk_dependencies"`
}

// Chunk information for breaking down large operations
type ChunkInfo struct {
	ID                 string                  `json:"id"`
	Name               string                  `json:"name"`
	Description        string                  `json:"description"`
	Dependencies       []string                `json:"dependencies"`
	EstimatedDuration  time.Duration           `json:"estimated_duration"`
	Status             string                  `json:"status"` // pending, running, completed, failed
	StartTime          time.Time               `json:"start_time"`
	EndTime            time.Time               `json:"end_time"`
	OutputFiles        []string                `json:"output_files"`
	LogicalOrder       int                     `json:"logical_order"`
}

// Terminal logging with colors and progress indicators
type TerminalLogger struct {
	logFile           *os.File
	colors            map[string]string
	showProgress      bool
	currentOperation  string
	mutex             sync.Mutex
}

// Initialize enhanced generator
func NewEnhancedSequentialGenerator() *EnhancedSequentialGenerator {
	sessionID := fmt.Sprintf("session_%d", time.Now().Unix())
	
	generator := &EnhancedSequentialGenerator{
		Model:            "llama3.2",
		OutputDir:        "output/books",
		TotalBooks:       10,
		ChunkSize:        3, // Process 3 books at a time
		AutoSaveInterval: 30 * time.Second,
		pauseChannel:     make(chan bool, 1),
		stopChannel:      make(chan bool, 1),
		resumeChannel:    make(chan bool, 1),
		stateFile:        fmt.Sprintf("enhanced_generator_state_%s.json", sessionID),
	}
	
	// Initialize session state
	generator.SessionState = &SessionState{
		SessionID:        sessionID,
		StartTime:        time.Now(),
		LastSaveTime:     time.Now(),
		CurrentOperation: "initializing",
		BooksCompleted:   []int{},
		BooksFailed:      []int{},
		CanResume:        true,
		ResumePoint: ResumePoint{
			BookNumber:     1,
			PhaseNumber:    1,
			Operation:      "start",
			CompletedSteps: []string{},
			NextSteps:      []string{"load_themes", "setup_phases", "start_generation"},
		},
	}
	
	// Setup enhanced phases with chunking
	generator.setupEnhancedPhases()
	
	// Initialize progress tracker
	generator.ProgressTracker = NewProgressTracker(generator.TotalBooks, generator.OutputDir)
	
	return generator
}

// Setup signal handlers for graceful pause/stop
func (g *EnhancedSequentialGenerator) setupSignalHandlers() {
	signalChannel := make(chan os.Signal, 1)
	signal.Notify(signalChannel, syscall.SIGINT, syscall.SIGTERM, syscall.SIGUSR1, syscall.SIGUSR2)
	
	go func() {
		for sig := range signalChannel {
			switch sig {
			case syscall.SIGINT:
				g.logger.LogImportant("üìã SIGINT received - Initiating graceful stop...")
				g.GracefulStop()
			case syscall.SIGTERM:
				g.logger.LogImportant("üõë SIGTERM received - Forcing stop...")
				g.ForceStop()
			case syscall.SIGUSR1:
				g.logger.LogImportant("‚è∏Ô∏è  SIGUSR1 received - Pausing...")
				g.Pause()
			case syscall.SIGUSR2:
				g.logger.LogImportant("‚ñ∂Ô∏è  SIGUSR2 received - Resuming...")
				g.Resume()
			}
		}
	}()
}

// Enhanced terminal logger
func NewTerminalLogger(logDir string) *TerminalLogger {
	// Ensure log directory exists
	os.MkdirAll(logDir, 0755)
	
	logFile, err := os.OpenFile(
		filepath.Join(logDir, fmt.Sprintf("generation_log_%d.txt", time.Now().Unix())),
		os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
	if err != nil {
		fmt.Printf("‚ö†Ô∏è  Warning: Could not create log file: %v
", err)
	}
	
	colors := map[string]string{
		"reset":     "[0m",
		"red":       "[31m",
		"green":     "[32m",
		"yellow":    "[33m",
		"blue":      "[34m",
		"magenta":   "[35m",
		"cyan":      "[36m",
		"white":     "[37m",
		"bold":      "[1m",
		"underline": "[4m",
	}
	
	return &TerminalLogger{
		logFile:      logFile,
		colors:       colors,
		showProgress: true,
	}
}

func (tl *TerminalLogger) LogProgress(operation, details string, percentage float64) {
	tl.mutex.Lock()
	defer tl.mutex.Unlock()
	
	timestamp := time.Now().Format("15:04:05")
	progressBar := tl.createProgressBar(percentage)
	
	message := fmt.Sprintf("%s[%s]%s %süîÑ %s%s%s %s(%.1f%%) %s%s%s
",
		tl.colors["cyan"], timestamp, tl.colors["reset"],
		tl.colors["bold"], operation, tl.colors["reset"],
		tl.colors["yellow"], progressBar, percentage, tl.colors["reset"],
		tl.colors["white"], details, tl.colors["reset"])
	
	fmt.Print(message)
	
	if tl.logFile != nil {
		tl.logFile.WriteString(fmt.Sprintf("[%s] PROGRESS: %s (%.1f%%) - %s
", timestamp, operation, percentage, details))
	}
	
	tl.currentOperation = operation
}

func (tl *TerminalLogger) LogSuccess(operation, details string) {
	tl.mutex.Lock()
	defer tl.mutex.Unlock()
	
	timestamp := time.Now().Format("15:04:05")
	message := fmt.Sprintf("%s[%s]%s %s‚úÖ SUCCESS:%s %s%s%s - %s%s%s
",
		tl.colors["cyan"], timestamp, tl.colors["reset"],
		tl.colors["green"], tl.colors["reset"],
		tl.colors["bold"], operation, tl.colors["reset"],
		tl.colors["white"], details, tl.colors["reset"])
	
	fmt.Print(message)
	
	if tl.logFile != nil {
		tl.logFile.WriteString(fmt.Sprintf("[%s] SUCCESS: %s - %s
", timestamp, operation, details))
	}
}

func (tl *TerminalLogger) LogError(operation, details string) {
	tl.mutex.Lock()
	defer tl.mutex.Unlock()
	
	timestamp := time.Now().Format("15:04:05")
	message := fmt.Sprintf("%s[%s]%s %s‚ùå ERROR:%s %s%s%s - %s%s%s
",
		tl.colors["cyan"], timestamp, tl.colors["reset"],
		tl.colors["red"], tl.colors["reset"],
		tl.colors["bold"], operation, tl.colors["reset"],
		tl.colors["white"], details, tl.colors["reset"])
	
	fmt.Print(message)
	
	if tl.logFile != nil {
		tl.logFile.WriteString(fmt.Sprintf("[%s] ERROR: %s - %s
", timestamp, operation, details))
	}
}

func (tl *TerminalLogger) LogInfo(operation, details string) {
	tl.mutex.Lock()
	defer tl.mutex.Unlock()
	
	timestamp := time.Now().Format("15:04:05")
	message := fmt.Sprintf("%s[%s]%s %s‚ÑπÔ∏è  INFO:%s %s%s%s - %s%s%s
",
		tl.colors["cyan"], timestamp, tl.colors["reset"],
		tl.colors["blue"], tl.colors["reset"],
		tl.colors["bold"], operation, tl.colors["reset"],
		tl.colors["white"], details, tl.colors["reset"])
	
	fmt.Print(message)
	
	if tl.logFile != nil {
		tl.logFile.WriteString(fmt.Sprintf("[%s] INFO: %s - %s
", timestamp, operation, details))
	}
}

func (tl *TerminalLogger) LogImportant(message string) {
	tl.mutex.Lock()
	defer tl.mutex.Unlock()
	
	timestamp := time.Now().Format("15:04:05")
	formattedMessage := fmt.Sprintf("%s[%s]%s %s%s%s %s%s%s
",
		tl.colors["cyan"], timestamp, tl.colors["reset"],
		tl.colors["bold"], tl.colors["magenta"], message,
		tl.colors["reset"], tl.colors["reset"], tl.colors["reset"])
	
	fmt.Print(formattedMessage)
	
	if tl.logFile != nil {
		tl.logFile.WriteString(fmt.Sprintf("[%s] IMPORTANT: %s
", timestamp, message))
	}
}

func (tl *TerminalLogger) createProgressBar(percentage float64) string {
	barLength := 20
	filledLength := int(percentage / 100.0 * float64(barLength))
	
	bar := strings.Repeat("‚ñà", filledLength) + strings.Repeat("‚ñë", barLength-filledLength)
	return fmt.Sprintf("[%s]", bar)
}

func (tl *TerminalLogger) Close() {
	if tl.logFile != nil {
		tl.logFile.Close()
	}
}

// Setup enhanced phases with chunking capabilities
func (g *EnhancedSequentialGenerator) setupEnhancedPhases() {
	g.Phases = []PhaseInfo{
		{1, "Phase 1 Beta", "phase1_beta", "Market Intelligence & USP Optimization", "", "usp_optimization.json"},
		{2, "Phase 2", "phase2", "Concept Generation & Validation", "usp_optimization.json", "concepts.json"},
		{3, "Phase 3", "phase3", "Reader Feedback & Shareability", "concepts.json", "feedback.json"},
		{4, "Phase 4", "phase4", "Media Coverage & PR Analysis", "feedback.json", "media.json"},
		{5, "Phase 5", "phase5", "Title Optimization & A/B Testing", "media.json", "titles.json"},
		{6, "Phase 6 Beta", "phase6_beta", "Complete Content Generation", "titles.json", "content.json"},
		{7, "Phase 7", "phase7", "Marketing Assets & Campaign", "content.json", "marketing.json"},
	}
}

// Add logger field to the enhanced generator
type EnhancedSequentialGeneratorWithLogger struct {
	*EnhancedSequentialGenerator
	logger *TerminalLogger
}

// Removed duplicate main function - keeping the one with command line argument support

// Enhanced banner
func showEnhancedBanner() {
	fmt.Println(`
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó          ‚ïë
‚ïë  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó         ‚ïë
‚ïë  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë         ‚ïë
‚ïë  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë         ‚ïë
‚ïë  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù         ‚ïë
‚ïë  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù          ‚ïë
‚ïë                                                                               ‚ïë
‚ïë        üìö ENHANCED SEQUENTIAL BOOK GENERATION SYSTEM üìö                       ‚ïë
‚ïë                                                                               ‚ïë
‚ïë    ‚ú® Features: Resume ‚Ä¢ Pause ‚Ä¢ Real-time Logging ‚Ä¢ Chunked Processing ‚ú®    ‚ïë
‚ïë                                                                               ‚ïë
‚ïë                        Co-authored by animality.ai                           ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
`)
}

// Check for existing state
func (g *EnhancedSequentialGenerator) checkForExistingState() bool {
	if _, err := os.Stat(g.stateFile); os.IsNotExist(err) {
		return false
	}
	
	// Try to load state file
	data, err := os.ReadFile(g.stateFile)
	if err != nil {
		g.logger.LogError("State Check", fmt.Sprintf("Could not read state file: %v", err))
		return false
	}
	
	var existingState EnhancedSequentialGenerator
	if err := json.Unmarshal(data, &existingState); err != nil {
		g.logger.LogError("State Check", fmt.Sprintf("Could not parse state file: %v", err))
		return false
	}
	
	return existingState.SessionState.CanResume
}

// Ask user for resumption
func (g *EnhancedSequentialGenerator) askForResumption() bool {
	fmt.Print("
üîÑ Previous session found. Resume from where you left off? (y/n): ")
	
	scanner := bufio.NewScanner(os.Stdin)
	scanner.Scan()
	response := strings.ToLower(strings.TrimSpace(scanner.Text()))
	
	return response == "y" || response == "yes"
}

// Resume from existing state
func (g *EnhancedSequentialGenerator) resumeFromState() {
	data, err := os.ReadFile(g.stateFile)
	if err != nil {
		g.logger.LogError("Resume", fmt.Sprintf("Could not read state file: %v", err))
		return
	}
	
	if err := json.Unmarshal(data, g); err != nil {
		g.logger.LogError("Resume", fmt.Sprintf("Could not parse state file: %v", err))
		return
	}
	
	// Restore non-JSON fields
	g.pauseChannel = make(chan bool, 1)
	g.stopChannel = make(chan bool, 1)
	g.resumeChannel = make(chan bool, 1)
	
	g.logger.LogSuccess("Resume", fmt.Sprintf("Resumed session %s from book %d, phase %d", 
		g.SessionState.SessionID, 
		g.SessionState.ResumePoint.BookNumber, 
		g.SessionState.ResumePoint.PhaseNumber))
}

// Initialize fresh session
func (g *EnhancedSequentialGenerator) initializeFreshSession() {
	g.SessionState.StartTime = time.Now()
	g.SessionState.CurrentOperation = "initializing"
	g.saveState()
}

// Display configuration
func (g *EnhancedSequentialGenerator) displayConfiguration() {
	g.logger.LogInfo("Configuration", fmt.Sprintf("Session ID: %s", g.SessionState.SessionID))
	g.logger.LogInfo("Configuration", fmt.Sprintf("Total books: %d", g.TotalBooks))
	g.logger.LogInfo("Configuration", fmt.Sprintf("AI Model: %s", g.Model))
	g.logger.LogInfo("Configuration", fmt.Sprintf("Output directory: %s", g.OutputDir))
	g.logger.LogInfo("Configuration", fmt.Sprintf("Chunk size: %d books", g.ChunkSize))
	g.logger.LogInfo("Configuration", fmt.Sprintf("Auto-save interval: %v", g.AutoSaveInterval))
	g.logger.LogInfo("Configuration", fmt.Sprintf("Phases per book: %d", len(g.Phases)))
	
	g.logger.LogInfo("Book Queue", "Selected themes:")
	for i, theme := range g.BookQueue {
		g.logger.LogInfo("Book Queue", fmt.Sprintf("  %d. %s (%s)", i+1, theme.Title, theme.Category))
		g.logger.LogInfo("Book Queue", fmt.Sprintf("     "%s"", theme.MemorablePhrase))
	}
}

// Auto-save routine
func (g *EnhancedSequentialGenerator) autoSaveRoutine() {
	ticker := time.NewTicker(g.AutoSaveInterval)
	defer ticker.Stop()
	
	for {
		select {
		case <-ticker.C:
			g.saveState()
		case <-g.stopChannel:
			return
		}
	}
}

// Command listener for interactive control
func (g *EnhancedSequentialGenerator) commandListener() {
	scanner := bufio.NewScanner(os.Stdin)
	
	for scanner.Scan() {
		command := strings.ToLower(strings.TrimSpace(scanner.Text()))
		
		switch command {
		case "pause":
			g.Pause()
		case "resume":
			g.Resume()
		case "stop":
			g.GracefulStop()
		case "status":
			g.DisplayStatus()
		case "save":
			g.saveState()
			g.logger.LogSuccess("Command", "State saved manually")
		case "help":
			g.displayHelp()
		default:
			if command != "" {
				g.logger.LogInfo("Command", fmt.Sprintf("Unknown command: %s (type 'help' for available commands)", command))
			}
		}
		
		if g.stopped {
			break
		}
	}
}

// Display help
func (g *EnhancedSequentialGenerator) displayHelp() {
	fmt.Println("
üìã Available Commands:")
	fmt.Println("   pause  - Pause generation after current operation")
	fmt.Println("   resume - Resume paused generation")
	fmt.Println("   stop   - Gracefully stop generation and save state")
	fmt.Println("   status - Display current generation status")
	fmt.Println("   save   - Manually save current state")
	fmt.Println("   help   - Display this help message")
	fmt.Println()
}

// Pause generation
func (g *EnhancedSequentialGenerator) Pause() {
	g.mutex.Lock()
	defer g.mutex.Unlock()
	
	if g.paused {
		g.logger.LogInfo("Pause", "Generation is already paused")
		return
	}
	
	g.paused = true
	g.SessionState.CurrentOperation = "paused"
	g.saveState()
	
	g.logger.LogImportant("‚è∏Ô∏è  Generation paused. Type 'resume' to continue.")
	
	select {
	case g.pauseChannel <- true:
	default:
	}
}

// Resume generation
func (g *EnhancedSequentialGenerator) Resume() {
	g.mutex.Lock()
	defer g.mutex.Unlock()
	
	if !g.paused {
		g.logger.LogInfo("Resume", "Generation is not paused")
		return
	}
	
	g.paused = false
	g.SessionState.CurrentOperation = "resuming"
	g.saveState()
	
	g.logger.LogImportant("‚ñ∂Ô∏è  Generation resumed.")
	
	select {
	case g.resumeChannel <- true:
	default:
	}
}

// Graceful stop
func (g *EnhancedSequentialGenerator) GracefulStop() {
	g.mutex.Lock()
	defer g.mutex.Unlock()
	
	if g.stopped {
		return
	}
	
	g.stopped = true
	g.SessionState.CurrentOperation = "stopping"
	g.SessionState.CanResume = true
	g.saveState()
	
	g.logger.LogImportant("üõë Graceful stop initiated. Current progress will be saved.")
	
	select {
	case g.stopChannel <- true:
	default:
	}
}

// Force stop
func (g *EnhancedSequentialGenerator) ForceStop() {
	g.mutex.Lock()
	defer g.mutex.Unlock()
	
	g.stopped = true
	g.SessionState.CurrentOperation = "force_stopped"
	g.SessionState.CanResume = false
	
	g.logger.LogImportant("üö® Force stop initiated. Exiting immediately.")
	os.Exit(1)
}

// Display current status
func (g *EnhancedSequentialGenerator) DisplayStatus() {
	g.mutex.RLock()
	defer g.mutex.RUnlock()
	
	fmt.Println("
üìä Current Generation Status:")
	fmt.Printf("   Session ID: %s
", g.SessionState.SessionID)
	fmt.Printf("   Operation: %s
", g.SessionState.CurrentOperation)
	fmt.Printf("   Paused: %v
", g.paused)
	fmt.Printf("   Books Completed: %d/%d
", len(g.SessionState.BooksCompleted), g.TotalBooks)
	fmt.Printf("   Books Failed: %d
", len(g.SessionState.BooksFailed))
	fmt.Printf("   Current Book: %d
", g.SessionState.ResumePoint.BookNumber)
	fmt.Printf("   Current Phase: %d
", g.SessionState.ResumePoint.PhaseNumber)
	fmt.Printf("   Runtime: %v
", time.Since(g.SessionState.StartTime))
	
	if g.SessionState.CurrentBookState != nil {
		fmt.Printf("   Current Book Title: %s
", g.SessionState.CurrentBookState.Theme.Title)
		fmt.Printf("   Current Book Status: %s
", g.SessionState.CurrentBookState.Status)
	}
	
	fmt.Println()
}

// Start chunked generation process
func (g *EnhancedSequentialGenerator) startChunkedGeneration() {
	totalBooks := len(g.BookQueue)
	
	// Process books in chunks
	for i := 0; i < totalBooks; i += g.ChunkSize {
		// Check for stop/pause
		if g.checkControlSignals() {
			return
		}
		
		endIndex := i + g.ChunkSize
		if endIndex > totalBooks {
			endIndex = totalBooks
		}
		
		chunk := g.BookQueue[i:endIndex]
		chunkNumber := (i / g.ChunkSize) + 1
		totalChunks := (totalBooks + g.ChunkSize - 1) / g.ChunkSize
		
		g.logger.LogProgress("Chunk Processing", 
			fmt.Sprintf("Starting chunk %d/%d (%d books)", chunkNumber, totalChunks, len(chunk)),
			float64(i)/float64(totalBooks)*100.0)
		
		// Process chunk with logical flow preservation
		g.processBookChunk(chunk, i+1, chunkNumber, totalChunks)
		
		// Brief pause between chunks (unless this is the last chunk)
		if endIndex < totalBooks && !g.stopped {
			g.logger.LogInfo("Chunk Processing", "Brief pause between chunks...")
			time.Sleep(5 * time.Second)
		}
	}
}

// Process a chunk of books while maintaining logical flow
func (g *EnhancedSequentialGenerator) processBookChunk(chunk []BookTheme, startBookNumber, chunkNumber, totalChunks int) {
	for i, theme := range chunk {
		bookNumber := startBookNumber + i
		
		// Check for control signals
		if g.checkControlSignals() {
			return
		}
		
		// Update session state
		g.SessionState.ResumePoint.BookNumber = bookNumber
		g.SessionState.ResumePoint.PhaseNumber = 1
		g.SessionState.ResumePoint.Operation = "book_generation"
		g.SessionState.CurrentOperation = fmt.Sprintf("Generating book %d", bookNumber)
		
		g.logger.LogProgress("Book Generation", 
			fmt.Sprintf("Book %d/%d: %s", bookNumber, g.TotalBooks, theme.Title),
			float64(bookNumber-1)/float64(g.TotalBooks)*100.0)
		
		// Start tracking this book
		g.ProgressTracker.StartBook(bookNumber, theme)
		
		// Process book with enhanced error handling and resumption
		success := g.processBookWithResumption(theme, bookNumber)
		
		if success {
			g.SessionState.BooksCompleted = append(g.SessionState.BooksCompleted, bookNumber)
			g.logger.LogSuccess("Book Generation", fmt.Sprintf("Book %d completed successfully", bookNumber))
		} else {
			g.SessionState.BooksFailed = append(g.SessionState.BooksFailed, bookNumber)
			g.logger.LogError("Book Generation", fmt.Sprintf("Book %d failed", bookNumber))
		}
		
		// Save state after each book
		g.saveState()
		
		// Check if we should continue
		if g.stopped {
			return
		}
	}
}

// Process book with resumption capability
func (g *EnhancedSequentialGenerator) processBookWithResumption(theme BookTheme, bookNumber int) bool {
	// Create enhanced book state
	bookState := &BookGenerationState{
		BookNumber:      bookNumber,
		Theme:           theme,
		CurrentPhase:    0,
		PhaseResults:    make(map[string]interface{}),
		StartTime:       time.Now(),
		LastUpdateTime:  time.Now(),
		Status:          "starting",
		OutputDirectory: fmt.Sprintf("%s/book_%03d", g.OutputDir, bookNumber),
	}
	
	g.SessionState.CurrentBookState = bookState
	
	// Create output directory
	if err := os.MkdirAll(bookState.OutputDirectory, 0755); err != nil {
		g.logger.LogError("Directory Creation", fmt.Sprintf("Error creating output directory: %v", err))
		return false
	}
	
	// Step 1: Generate outline with progress tracking
	g.logger.LogProgress("Outline Generation", fmt.Sprintf("Generating 1000-word outline for book %d", bookNumber), 5.0)
	
	outline, err := GenerateBookOutline(theme, g.Model)
	if err != nil {
		g.logger.LogError("Outline Generation", fmt.Sprintf("Error generating outline: %v", err))
		return false
	}
	
	bookState.Outline = outline
	g.ProgressTracker.UpdateOutlineGenerated(outline.WordCount, 8.5) // Assume good quality for now
	
	// Save outline
	_, err = SaveOutline(outline, bookNumber)
	if err != nil {
		g.logger.LogError("Outline Saving", fmt.Sprintf("Error saving outline: %v", err))
		return false
	}
	
	g.logger.LogSuccess("Outline Generation", fmt.Sprintf("Generated %d-word outline", outline.WordCount))
	
	// Step 2: Process through phases with chunking and resumption
	for _, phase := range g.Phases {
		// Check for control signals
		if g.checkControlSignals() {
			return false
		}
		
		// Update resume point
		g.SessionState.ResumePoint.PhaseNumber = phase.Number
		g.SessionState.ResumePoint.Operation = fmt.Sprintf("phase_%d", phase.Number)
		
		bookState.CurrentPhase = phase.Number
		bookState.Status = fmt.Sprintf("processing_phase_%d", phase.Number)
		
		g.logger.LogProgress("Phase Processing", 
			fmt.Sprintf("Book %d - Phase %d: %s", bookNumber, phase.Number, phase.Description),
			(float64(bookNumber-1)+float64(phase.Number-1)/float64(len(g.Phases)))/float64(g.TotalBooks)*100.0)
		
		g.ProgressTracker.StartPhase(phase.Number, phase.Name)
		
		// Execute phase with chunking if applicable
		success := g.executePhaseWithChunking(phase, bookState)
		
		if success {
			// Mock quality scores and improvements for now
			qualityScores := map[string]float64{
				"content_quality": 8.0 + float64(phase.Number)*0.2,
				"market_viability": 7.5,
				"reader_engagement": 8.2,
			}
			improvements := []string{
				fmt.Sprintf("Enhanced %s capabilities", phase.Name),
				"Improved logical flow",
				"Better integration with previous phases",
			}
			outputFiles := []string{
				filepath.Join(bookState.OutputDirectory, fmt.Sprintf("phase%d_%s", phase.Number, phase.OutputFile)),
			}
			
			g.ProgressTracker.CompletePhase(phase.Number, outputFiles, improvements, qualityScores)
			g.logger.LogSuccess("Phase Processing", fmt.Sprintf("Phase %d completed", phase.Number))
		} else {
			g.ProgressTracker.FailPhase(phase.Number, "Phase execution failed")
			g.logger.LogError("Phase Processing", fmt.Sprintf("Phase %d failed", phase.Number))
			return false
		}
		
		// Save progress after each phase
		g.saveState()
		
		// Brief pause between phases
		time.Sleep(1 * time.Second)
	}
	
	// Complete the book
	finalFiles := []string{
		filepath.Join(bookState.OutputDirectory, "book_summary.json"),
		filepath.Join(bookState.OutputDirectory, "complete_content.md"),
	}
	
	g.ProgressTracker.CompleteBook(finalFiles)
	
	// Generate book completion summary
	g.generateEnhancedBookSummary(bookState)
	
	return true
}

// Execute phase with chunking capability
func (g *EnhancedSequentialGenerator) executePhaseWithChunking(phase PhaseInfo, bookState *BookGenerationState) bool {
	startTime := time.Now()
	
	// Change to phase directory
	originalDir, _ := os.Getwd()
	defer os.Chdir(originalDir)
	
	if err := os.Chdir(phase.Directory); err != nil {
		g.logger.LogError("Phase Execution", fmt.Sprintf("Failed to change to directory %s: %v", phase.Directory, err))
		return false
	}
	
	// Check if binary exists, build if necessary
	binaryName := phase.Directory
	if _, err := os.Stat(binaryName); os.IsNotExist(err) {
		g.logger.LogProgress("Building", fmt.Sprintf("Building %s binary", phase.Name), 0.0)
		buildCmd := exec.Command("go", "build", "-o", binaryName, "main.go")
		if err := buildCmd.Run(); err != nil {
			g.logger.LogError("Build", fmt.Sprintf("Build failed for %s: %v", phase.Name, err))
			return false
		}
		g.logger.LogSuccess("Building", fmt.Sprintf("Successfully built %s", phase.Name))
	}
	
	// Set up environment variables
	cmd := exec.Command("./"+binaryName)
	cmd.Env = append(os.Environ(),
		fmt.Sprintf("BOOK_TITLE=%s", bookState.Theme.Title),
		fmt.Sprintf("BOOK_DESCRIPTION=%s", bookState.Theme.Description),
		fmt.Sprintf("BOOK_PHRASE=%s", bookState.Theme.MemorablePhrase),
		fmt.Sprintf("BOOK_CATEGORY=%s", bookState.Theme.Category),
		fmt.Sprintf("BOOK_NUMBER=%03d", bookState.BookNumber),
		fmt.Sprintf("OUTLINE_AVAILABLE=true"),
		fmt.Sprintf("OUTPUT_DIR=%s", bookState.OutputDirectory),
		"AUTOMATED_MODE=true",
		fmt.Sprintf("OLLAMA_MODEL=%s", g.Model),
	)
	
	// Execute with timeout and progress monitoring
	g.logger.LogProgress("Phase Execution", fmt.Sprintf("Executing %s", phase.Name), 0.0)
	
	// Create a context for timeout handling
	output, err := cmd.CombinedOutput()
	
	duration := time.Since(startTime)
	
	if err != nil {
		g.logger.LogError("Phase Execution", fmt.Sprintf("Execution failed after %v: %v", duration, err))
		g.logger.LogError("Phase Output", string(output))
		return false
	}
	
	g.logger.LogSuccess("Phase Execution", fmt.Sprintf("Completed in %v", duration))
	
	// Verify output file was created and copy if it exists
	if phase.OutputFile != "" {
		// Try multiple possible locations for the output file
		possiblePaths := []string{
			phase.OutputFile,                                                    // Current directory
			filepath.Join(bookState.OutputDirectory, phase.OutputFile),         // Book directory
			filepath.Join(phase.Directory, phase.OutputFile),                   // Phase directory
			fmt.Sprintf("phase%d/%s", phase.Number, phase.OutputFile),         // Phase number directory
		}
		
		var foundPath string
		for _, path := range possiblePaths {
			if _, err := os.Stat(path); err == nil {
				foundPath = path
				break
			}
		}
		
		if foundPath != "" {
			// Copy output file to book directory with phase prefix
			bookOutputFile := filepath.Join(bookState.OutputDirectory, fmt.Sprintf("phase%d_%s", phase.Number, filepath.Base(phase.OutputFile)))
			if err := copyFile(foundPath, bookOutputFile); err != nil {
				g.logger.LogError("File Copy", fmt.Sprintf("Could not copy from %s: %v", foundPath, err))
			} else {
				g.logger.LogSuccess("File Copy", fmt.Sprintf("Output file copied: %s", bookOutputFile))
			}
		} else {
			// File not found, but don't treat as error since phases might not always generate files
			g.logger.LogInfo("File Check", fmt.Sprintf("Phase output file not found (this is normal): %s", phase.OutputFile))
		}
	}
	
	return true
}

// Check control signals (pause/stop)
func (g *EnhancedSequentialGenerator) checkControlSignals() bool {
	select {
	case <-g.pauseChannel:
		g.logger.LogImportant("‚è∏Ô∏è  Generation paused. Waiting for resume signal...")
		
		// Wait for resume or stop
		select {
		case <-g.resumeChannel:
			g.logger.LogImportant("‚ñ∂Ô∏è  Generation resumed.")
			return false
		case <-g.stopChannel:
			g.logger.LogImportant("üõë Generation stopped.")
			return true
		}
		
	case <-g.stopChannel:
		g.logger.LogImportant("üõë Generation stopped.")
		return true
		
	default:
		// Check if paused
		g.mutex.RLock()
		isPaused := g.paused
		isStopped := g.stopped
		g.mutex.RUnlock()
		
		if isPaused {
			g.logger.LogImportant("‚è∏Ô∏è  Generation is paused. Waiting for resume...")
			
			// Wait for resume or stop
			select {
			case <-g.resumeChannel:
				g.logger.LogImportant("‚ñ∂Ô∏è  Generation resumed.")
				return false
			case <-g.stopChannel:
				g.logger.LogImportant("üõë Generation stopped.")
				return true
			}
		}
		
		return isStopped
	}
	
	return false
}

// Save current state
func (g *EnhancedSequentialGenerator) saveState() {
	g.mutex.RLock()
	defer g.mutex.RUnlock()
	
	g.SessionState.LastSaveTime = time.Now()
	
	data, err := json.MarshalIndent(g, "", "  ")
	if err != nil {
		g.logger.LogError("State Save", fmt.Sprintf("Could not marshal state: %v", err))
		return
	}
	
	// Create backup of existing state
	if _, err := os.Stat(g.stateFile); err == nil {
		backupFile := g.stateFile + ".backup"
		os.Rename(g.stateFile, backupFile)
	}
	
	if err := os.WriteFile(g.stateFile, data, 0644); err != nil {
		g.logger.LogError("State Save", fmt.Sprintf("Could not save state: %v", err))
		return
	}
	
	// Also save a timestamped backup
	timestampedFile := fmt.Sprintf("%s.%d", g.stateFile, time.Now().Unix())
	os.WriteFile(timestampedFile, data, 0644)
}

// Generate enhanced book summary
func (g *EnhancedSequentialGenerator) generateEnhancedBookSummary(bookState *BookGenerationState) {
	summaryFile := filepath.Join(bookState.OutputDirectory, "enhanced_book_summary.json")
	
	// Get outline word count safely
	outlineWords := 0
	if bookState.Outline != nil {
		outlineWords = bookState.Outline.WordCount
	}

	summary := map[string]interface{}{
		"book_number":       bookState.BookNumber,
		"title":            bookState.Theme.Title,
		"memorable_phrase":  bookState.Theme.MemorablePhrase,
		"category":         bookState.Theme.Category,
		"outline_words":    outlineWords,
		"phases_completed": len(g.Phases),
		"total_duration":   time.Since(bookState.StartTime).String(),
		"generated_at":     time.Now().Format(time.RFC3339),
		"status":           "completed",
		"session_id":       g.SessionState.SessionID,
		"generation_method": "enhanced_sequential_7_phase",
		"quality_metrics":   g.ProgressTracker.CurrentBook.QualityMetrics,
	}
	
	summaryData, _ := json.MarshalIndent(summary, "", "  ")
	os.WriteFile(summaryFile, summaryData, 0644)
	
	g.logger.LogSuccess("Summary Generation", "Enhanced book summary created")
}

// Helper function to copy files
func copyFile(src, dst string) error {
	data, err := os.ReadFile(src)
	if err != nil {
		return err
	}
	return os.WriteFile(dst, data, 0644)
}

// Load book themes (reuse from original implementation)
func loadBookThemes() ([]BookTheme, error) {
	themes := []BookTheme{
		{1, "AI for SMBs: Automate Your Business in 7 Days (No Tech Background Required)", "This title is highly appealing due to its promise of quick, tangible results ('7 Days'), a clear benefit ('Automate Your Business'), and addresses a common fear ('No Tech Background Required'). It directly aligns with Automality's efficiency focus for SMBs.", "AI & Business", "Why it's top: This title is highly appealing due to its promise of quick, tangible results ('7 Days'), a clear benefit ('Automate Your Business'), and addresses a common fear ('No Tech Background Required'). It directly aligns with Automality's efficiency focus for SMBs."},
		{2, "Beyond Manual: How AI Can Free Up 10+ Hours/Week for Your Small Business", "This title offers a specific, quantifiable benefit ('Free Up 10+ Hours/Week') which is a significant pain point for time-strapped SMBs. It highlights a direct solution to manual tasks.", "AI & Business", "Why it's top: This title offers a specific, quantifiable benefit ('Free Up 10+ Hours/Week') which is a significant pain point for time-strapped SMBs. It highlights a direct solution to manual tasks."},
		{3, "Your First AI Win: A Practical Playbook for SMB Marketing Automation", "This title focuses on achieving an 'easy win' in a crucial area for many SMBs ('Marketing Automation'). It's practical and promises a clear path to early success with AI.", "AI & Business", "Why it's top: This title focuses on achieving an 'easy win' in a crucial area for many SMBs ('Marketing Automation'). It's practical and promises a clear path to early success with AI."},
	}
	
	return themes, nil
}

// Select diverse themes across categories
func selectDiverseThemes(themes []BookTheme, count int) []BookTheme {
	if len(themes) <= count {
		return themes
	}
	
	return themes[:count] // Take first 'count' themes for now
}

// Parse command line arguments
func parseArgs() (int, string) {
	bookNum := 0
	mode := "normal"
	
	for i, arg := range os.Args[1:] {
		if strings.HasPrefix(arg, "--book=") {
			fmt.Sscanf(arg, "--book=%d", &bookNum)
		} else if strings.HasPrefix(arg, "--mode=") {
			mode = strings.TrimPrefix(arg, "--mode=")
		} else if arg == "--book" && i+1 < len(os.Args[1:]) {
			fmt.Sscanf(os.Args[i+2], "%d", &bookNum)
		}
	}
	
	return bookNum, mode
}

// Main function
func main() {
	// Parse command line arguments
	targetBook, mode := parseArgs()
	
	// Create enhanced generator
	generator := NewEnhancedSequentialGenerator()
	
	// Setup terminal logger
	generator.logger = NewTerminalLogger(filepath.Join(generator.OutputDir, "logs"))
	
	// Display startup banner
	showEnhancedBanner()
	
	// Handle specific book expansion mode
	if targetBook > 0 && mode == "expand" {
		generator.logger.LogImportant(fmt.Sprintf("üéØ SINGLE BOOK EXPANSION MODE - Book %d", targetBook))
		
		// Check if book exists and has outline
		bookDir := filepath.Join(generator.OutputDir, fmt.Sprintf("book_%03d", targetBook))
		if _, err := os.Stat(bookDir); os.IsNotExist(err) {
			generator.logger.LogError("Book Check", fmt.Sprintf("Book %d directory not found", targetBook))
			os.Exit(1)
		}
		
		// Check if already expanded
		expandedSummary := filepath.Join(bookDir, "EXPANDED_BOOK_SUMMARY.md")
		if _, err := os.Stat(expandedSummary); err == nil {
			generator.logger.LogSuccess("Book Check", fmt.Sprintf("Book %d already expanded", targetBook))
			generator.logger.LogInfo("Expansion Summary", expandedSummary)
			os.Exit(0)
		}
		
		// Load book themes to get book info
		themes, err := loadBookThemes()
		if err != nil {
			generator.logger.LogError("Theme Loading", fmt.Sprintf("Error loading themes: %v", err))
			os.Exit(1)
		}
		
		if targetBook > len(themes) {
			generator.logger.LogError("Book Check", fmt.Sprintf("Book %d not found in themes", targetBook))
			os.Exit(1)
		}
		
		// Set up for single book expansion
		generator.BookQueue = []BookTheme{themes[targetBook-1]}
		generator.TotalBooks = 1
		generator.CurrentBook = 1
		
		generator.logger.LogSuccess("Setup", fmt.Sprintf("Starting expansion for: %s", themes[targetBook-1].Title))
		
		// Start the expansion process
		generator.expandSingleBook(targetBook)
		
	} else {
		// Normal full generation mode
		generator.setupSignalHandlers()
		
		// Check for resumable state
		if generator.checkForExistingState() {
			if generator.askForResumption() {
				generator.logger.LogImportant("üîÑ Resuming from previous session...")
				generator.resumeFromState()
			} else {
				generator.logger.LogImportant("üÜï Starting fresh session...")
				generator.initializeFreshSession()
			}
		} else {
			generator.logger.LogImportant("üÜï Starting new session...")
			generator.initializeFreshSession()
		}
		
		// Load themes and start generation
		themes, err := loadBookThemes()
		if err != nil {
			generator.logger.LogError("Theme Loading", fmt.Sprintf("Error loading themes: %v", err))
			return
		}
		
		generator.BookQueue = selectDiverseThemes(themes, generator.TotalBooks)
		generator.logger.LogSuccess("Theme Selection", fmt.Sprintf("Selected %d diverse themes", len(generator.BookQueue)))
		
		// Start auto-save and command listener
		go generator.autoSaveRoutine()
		go generator.commandListener()
		
		// Start generation
		generator.logger.LogImportant("üöÄ Starting Enhanced Sequential Book Generation...")
		generator.startChunkedGeneration()
	}
}

// Expand a single book using the proper 7-phase system
func (g *EnhancedSequentialGenerator) expandSingleBook(bookNum int) {
	bookDir := filepath.Join(g.OutputDir, fmt.Sprintf("book_%03d", bookNum))
	
	g.logger.LogProgress("Book Generation", fmt.Sprintf("Starting 7-phase generation for book %d", bookNum), 0.0)
	
	// Load book theme for this book
	themes, err := loadBookThemes()
	if err != nil {
		g.logger.LogError("Theme Loading", fmt.Sprintf("Error loading themes: %v", err))
		return
	}
	
	if bookNum > len(themes) {
		g.logger.LogError("Book Validation", fmt.Sprintf("Book %d not found in themes", bookNum))
		return
	}
	
	// Load existing outline if available
	var outline *BookOutline
	outlineFile := filepath.Join(bookDir, "outline_1000_words.json")
	if outlineData, err := os.ReadFile(outlineFile); err == nil {
		outline = &BookOutline{}
		json.Unmarshal(outlineData, outline)
	}

	// Create book state for the 7-phase pipeline
	bookState := &BookGenerationState{
		BookNumber:      bookNum,
		Theme:           themes[bookNum-1],
		Outline:         outline,
		CurrentPhase:    0,
		PhaseResults:    make(map[string]interface{}),
		StartTime:       time.Now(),
		LastUpdateTime:  time.Now(),
		Status:          "in_progress",
		OutputDirectory: bookDir,
	}
	
	// Ensure book directory exists
	os.MkdirAll(bookDir, 0755)
	
	// Execute all 7 phases in sequence
	for i, phase := range g.Phases {
		progress := float64(i) / float64(len(g.Phases)) * 100
		g.logger.LogProgress("Phase Processing", fmt.Sprintf("Book %d - Phase %d: %s", bookNum, phase.Number, phase.Description), progress)
		
		// Execute phase
		success := g.executePhaseWithChunking(phase, bookState)
		if !success {
			g.logger.LogError("Phase Execution", fmt.Sprintf("Phase %d failed for book %d", phase.Number, bookNum))
			// Continue with remaining phases rather than stopping
		} else {
			g.logger.LogSuccess("Phase Processing", fmt.Sprintf("Phase %d completed", phase.Number))
		}
		
		// Update book state
		bookState.CurrentPhase = phase.Number
		bookState.LastUpdateTime = time.Now()
		
		// Save phase progress
		g.savePhaseProgress(bookState, phase)
	}
	
	// Generate final book summary
	g.generateEnhancedBookSummary(bookState)
	
	// Generate expansion summary
	g.generateExpansionSummary(bookNum, bookDir)
	
	g.logger.LogSuccess("Book Generation", fmt.Sprintf("üìö Book %d 7-phase generation completed!", bookNum))
}

// Save phase progress to JSON file
func (g *EnhancedSequentialGenerator) savePhaseProgress(bookState *BookGenerationState, phase PhaseInfo) {
	progress := map[string]interface{}{
		"book_number":       bookState.BookNumber,
		"book_title":        bookState.Theme.Title,
		"phase_number":      phase.Number,
		"phase_name":        phase.Name,
		"phase_description": phase.Description,
		"completed_at":      time.Now().Format(time.RFC3339),
		"phase_duration":    time.Since(bookState.LastUpdateTime).String(),
		"total_duration":    time.Since(bookState.StartTime).String(),
	}
	
	progressData, _ := json.MarshalIndent(progress, "", "  ")
	progressFile := filepath.Join(bookState.OutputDirectory, fmt.Sprintf("phase%d_progress.json", phase.Number))
	os.WriteFile(progressFile, progressData, 0644)
	
	g.logger.LogInfo("Progress Save", fmt.Sprintf("Phase %d progress saved", phase.Number))
}

// Expand chapter using Ollama
func (g *EnhancedSequentialGenerator) expandChapterWithOllama(bookNum, chapterNum int, bookDir string) error {
	// First, find the chapter directory using multiple naming patterns
	chapterDir := ""
	possibleDirs := []string{
		filepath.Join(bookDir, fmt.Sprintf("Chapter_%02d", chapterNum)),
		filepath.Join(bookDir, fmt.Sprintf("Chapter_%02d_%d_*", chapterNum, chapterNum)),
	}
	
	// Try to find existing chapter directory
	for _, pattern := range possibleDirs {
		if strings.Contains(pattern, "*") {
			matches, _ := filepath.Glob(pattern)
			if len(matches) > 0 {
				chapterDir = matches[0]
				break
			}
		} else {
			if _, err := os.Stat(pattern); err == nil {
				chapterDir = pattern
				break
			}
		}
	}
	
	// If no chapter directory found, generate chapter first
	if chapterDir == "" {
		g.logger.LogInfo("Chapter Generation", fmt.Sprintf("Chapter %d not found, generating from outline...", chapterNum))
		
		// Read outline to generate chapter
		outlineFile := filepath.Join(bookDir, "outline_1000_words.md")
		outline, err := os.ReadFile(outlineFile)
		if err != nil {
			return fmt.Errorf("could not read outline: %v", err)
		}
		
		// Create chapter directory
		chapterDir = filepath.Join(bookDir, fmt.Sprintf("Chapter_%02d_%d", chapterNum, chapterNum))
		os.MkdirAll(chapterDir, 0755)
		
		// Generate chapter content from outline
		chapterPrompt := fmt.Sprintf(`Based on this book outline, generate detailed content for Chapter %d. Make it a complete chapter with introduction, main content, and conclusion.

Book Outline:
%s

Generate a comprehensive Chapter %d with:
1. Clear chapter title
2. Engaging introduction 
3. Detailed main content (2000-3000 words)
4. Practical examples and case studies
5. Strong conclusion
6. Action items or key takeaways

Format as markdown.`, chapterNum, string(outline), chapterNum)
		
		// Call Ollama to generate chapter
		cmd := exec.Command("ollama", "run", g.Model)
		cmd.Stdin = strings.NewReader(chapterPrompt)
		
		chapterContent, err := cmd.Output()
		if err != nil {
			return fmt.Errorf("ollama chapter generation failed: %v", err)
		}
		
		// Save chapter content
		contentFile := filepath.Join(chapterDir, fmt.Sprintf("chapter_%02d_content.md", chapterNum))
		err = os.WriteFile(contentFile, chapterContent, 0644)
		if err != nil {
			return fmt.Errorf("could not save chapter content: %v", err)
		}
		
		g.logger.LogSuccess("Chapter Generation", fmt.Sprintf("Generated Chapter %d content", chapterNum))
	}
	
	// Read existing chapter content (try multiple file naming patterns)
	contentFiles := []string{
		filepath.Join(chapterDir, "chapter_content.md"),
		filepath.Join(chapterDir, fmt.Sprintf("chapter_%02d_content.md", chapterNum)),
	}
	
	var content []byte
	var contentFile string
	var err error
	
	for _, file := range contentFiles {
		if content, err = os.ReadFile(file); err == nil {
			contentFile = file
			break
		}
	}
	
	if contentFile == "" {
		return fmt.Errorf("could not find chapter content file in %s", chapterDir)
	}
	
	// Create expansion prompt
	prompt := fmt.Sprintf(`Expand this chapter with detailed stories, examples, and case studies. Make it engaging and narrative-driven with characters and real-world scenarios. Current content:

%s

Expand this to 3-4x the length with:
1. Detailed stories and case studies
2. Character development and narratives  
3. Real-world examples and scenarios
4. Enhanced descriptions and dialogue
5. Deeper exploration of concepts

Keep the same structure and core message but make it much more engaging and detailed.`, string(content))
	
	// Call Ollama for expansion
	cmd := exec.Command("ollama", "run", g.Model)
	cmd.Stdin = strings.NewReader(prompt)
	
	output, err := cmd.Output()
	if err != nil {
		return fmt.Errorf("ollama expansion failed: %v", err)
	}
	
	// Save expanded content
	expandedFile := filepath.Join(chapterDir, "chapter_content_expanded.md")
	err = os.WriteFile(expandedFile, output, 0644)
	if err != nil {
		return fmt.Errorf("could not save expanded content: %v", err)
	}
	
	return nil
}

// Generate expansion summary
func (g *EnhancedSequentialGenerator) generateExpansionSummary(bookNum int, bookDir string) {
	summaryContent := fmt.Sprintf(`# Book %d Expansion Summary

## Expansion Completed
- **Date**: %s
- **Expansion Method**: Enhanced Sequential Generator with Ollama
- **Mode**: Single Book Expansion

## Chapters Expanded
- Chapter 1: Enhanced with detailed stories and examples
- Chapter 2: Enhanced with detailed stories and examples  
- Chapter 3: Enhanced with detailed stories and examples
- Chapter 4: Enhanced with detailed stories and examples
- Chapter 5: Enhanced with detailed stories and examples
- Chapter 6: Enhanced with detailed stories and examples

## Enhancement Features
- ‚úÖ Detailed narratives and character development
- ‚úÖ Real-world case studies and examples
- ‚úÖ Enhanced dialogue and descriptions
- ‚úÖ Deeper concept exploration
- ‚úÖ Engaging storytelling elements

## Files Created
Each chapter now has both:
- Original content (chapter_content.md)
- Expanded content (chapter_content_expanded.md)

## Status
**EXPANSION COMPLETE** ‚ú®

Generated by Enhanced Sequential Book Generator
`, bookNum, time.Now().Format("2006-01-02 15:04:05"))

	summaryFile := filepath.Join(bookDir, "EXPANDED_BOOK_SUMMARY.md")
	os.WriteFile(summaryFile, []byte(summaryContent), 0644)
}
